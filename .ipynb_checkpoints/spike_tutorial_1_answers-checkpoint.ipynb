{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spike Tutorial -- Part 1\n",
    "\n",
    "## Data Description:\n",
    "\n",
    "This data set is recorded from auditory cortex in an awake mouse. This was a VGAT-cre mouse that was injected with a FLEX-ChR2 virus, which encodes an excitatory opsin that will selectively express in VGAT cells in this mouse line. The idea here is that when you shine blue light on the injection site, inhibitory VGAT neurons (VGAT is a pan-inhibitory neuronal marker) will activate, and through massive inhibition shut down most of the other neurons in the area.\n",
    "\n",
    "While there were several stimuli run during this recording, we will focus on only one of them: a set of dynamic random chord (DRC) stimuli which alternate between low and high contrast, interleaved with laser stimulation.\n",
    "\n",
    "    \n",
    "## Neural Data\n",
    "This is spiking data recorded from a laminar probe. We'll focus mostly on one neuron in this notebook, but there are about 50 neurons in this data set.\n",
    "\n",
    "If you're not familiar working with spike recordings, there a few important things you need:\n",
    "1. **The spike times:** here, these are contained in a file called spike_times.npy, and are coded in samples from the start of the recording.\n",
    "2. **Event times:** these are trigger times (typically in the form of 5 volt square pulses) that are locked to stimulus events (in our case, contrast transitions and laser pulse onsets and offsets).\n",
    "3. **Spike identity:** having a lot of spikes is not necessarily useful unless you know which neurons they come from. Spike identity is usually assigned during spike sorting.\n",
    "4. **Stimulus information:** knowing which stimulus was presented when is *essential*. The usual practice is to save some sort of stimulus index that assigns which stimulus is associated with which event time.\n",
    "\n",
    "Those are the basics, we'll cover the details as we go!\n",
    "\n",
    "First lets import useful modules that we're already familiar with (numpy, matplotlib, pandas, and os for path stuff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stimulus Events\n",
    "\n",
    "First we want to deal with stimulus events. With our recording system, there are a couple different types, I'll call them *messages* and *events*. First we'll focus on *messages*.\n",
    "\n",
    "*messages* are events that are manually typed into the recording computer at different parts of the recording. They're good for logging stimulus blocks, notes about recording quality, or errors. They have two important aspects, the text of the message and the time it was logged.\n",
    "\n",
    "The messages for this recording are saved in two files in the folder `'_data/messages'` called `'text.npy'` and `'timestamps.npy'`\n",
    "\n",
    "First define a filepath to your different files (HINT: `os.path.join` is useful here), then load them using `np.load`. Save the text in a variable called `msgText`, and the timestamps in a variable called `msgSample`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load message data\n",
    "root = '_data'\n",
    "\n",
    "msgText = np.load(os.path.join(root,'messages','text.npy'))\n",
    "msgSample = np.load(os.path.join(root,'messages','timestamps.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the contents of each, and note the type and shape. They are numpy arrays of the same size:\n",
    "- In the text array, each value is the text that I typed in to express something about the upcoming stimuli.\n",
    "- In the sample array is the timestamp for each of those text logs. \n",
    "\n",
    "Take special note of the values in `msgSample`... what kind of numbers are they? What do you think they correspond to? (we will come back to this shortly, but the variable name is a clue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgText.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets move on to the events: using the same methods as above, load the event files `'channel_states.npy'` and `'timestamps.npy'` from the `'_data/events'` folder. Name the variables `evState` and `evSample`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load event data\n",
    "evState = np.load(os.path.join(root,'events','channel_states.npy'))\n",
    "evSample = np.load(os.path.join(root,'events','timestamps.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing how to visualize the structure of the events is key in starting to build an analysis pipeline.\n",
    "\n",
    "The first way I typically visualize events is by plotting the absolute event times against the difference between each event.\n",
    "\n",
    "(side note: I will probably use the terms samples and clock times interchangeably, I apologize in advance)\n",
    "\n",
    "**Try this:**\n",
    "- assign event times on the x axis\n",
    "- event differences on y (HINT: there is an np function that can compute the **diff**erence between array values)\n",
    "- (take care to match the array lengths)\n",
    "- plot as black dots, and make the markersize pretty small, like 1 or 2\n",
    "- try and do it all in one line if you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x120022690>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# event exploration plot here:\n",
    "# %matplotlib qt\n",
    "plt.plot(evSample[:-1],np.diff(evSample),'k.',markersize=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the plot, what is the range of the x and y axis? It's pretty large, right? This is because all of the events are encoded in sample numbers, or, the number of ticks the clock on the recording computer made. We want to convert this to seconds, but to do this, we need to know the sample rate of the recording clock and the recording start time.\n",
    "\n",
    "To illustrate the meaning of the recording start time, look at the value of the first `evSample`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24205772"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evSample[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you loaded it correctly, it should be `24205772`. That is already pretty big! \n",
    "\n",
    "This is because the recording system records events relative to when the recording GUI was turned on. \n",
    "This means that you can have something generating events at all times, and even if you start and stop several different recordings the events are all aligned to the same clock.\n",
    "\n",
    "However, this poses a problem for us, as we want to know when these events occurred relative to the start of the current recording of interest, this is why we need to know the clock time of the recording start. We also need to know the sample rate of the recording clock, we can find this in the file `'_data/sync_messages.txt'`\n",
    "\n",
    "Open the file using textEdit (Mac) or Notepad (Windows), what do you see here? You should see a line that ends with `start time: 23089408@30000Hz`... that is our start time, followed by the sampling rate!\n",
    "\n",
    "But how do we programatically extract these things? It's kind of a pain, but you'll thank me later if you end up needing these data for a ton of recordings:\n",
    "\n",
    "**Try and load this file:**\n",
    "I used `np.genfromtxt`, it has a bunch of useful options, but the ones you'll need are dtype (what type of data is in this file?), skip_header (we want to skip the first line), and delimiter (note that each string is separated by spaces). Load the data to a variable called `recInfo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Processor:', 'Rhythm', 'FPGA', 'Id:', '100', 'subProcessor:', '0',\n",
       "       'start', 'time:', '23089408@30000Hz'], dtype='<U16')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load file contents\n",
    "recInfo = np.genfromtxt(os.path.join(root,'sync_messages.txt'),dtype='str',skip_header=1,delimiter=' ')\n",
    "recInfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at recInfo, if you loaded it correctly, you should see that each section of the second line of the file is now in an array, and you can see that the string we want `23089408@30000Hz` is right at the end, cool!\n",
    "\n",
    "We want to separate out these numbers though, **try the following**:\n",
    "- extract this last string from the recInfo array\n",
    "- split into the start time and the sample rate strings\n",
    "- and then save those two numbers as integers in variables called `startTime` and `fs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "recInfo = recInfo[-1]\n",
    "\n",
    "tmp = str.split(recInfo,'@')\n",
    "\n",
    "# extract start time and sample rate\n",
    "startTime = int(tmp[0])\n",
    "fs = int(tmp[1][:-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets revisit our `evSample` and `msgSample` variables... aka the sample numbers of our events, relative to when the GUI was turned on.\n",
    "\n",
    "We want to convert these to seconds from the start of our recording. How would you do this? (HINT: you need to use the recording `startTime` and `fs`).\n",
    "\n",
    "Convert these two variables to seconds, and save them in new variables, `evTS` and `msgTS`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert events, messages to seconds\n",
    "evTS = (evSample - startTime) / fs\n",
    "msgTS = (msgSample - startTime) / fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all that, we're finally ready to look at our events in seconds! Make the same event difference plot as above, but with our new `evTS` variable. Label the axes as x 'Time (s)' and y 'dt (s)'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'dt (s)')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ready to look at the events in seconds now!\n",
    "plt.plot(evTS[:-1],np.diff(evTS),'k.',markersize=1)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('dt (s)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the plot, there are several different 'chunks' of similar events: these correspond to different stimulus blocks, where different types of stimuli were played. I typically try to use the messages to show the start of a block.\n",
    "\n",
    "**Lets visualize this:**\n",
    "On top of your evTS plot, plot a vertical red line where each `msgTS` occurred. For visualization, let's just make each line go from [0,30] on the y axis. I found this was simple to do with a loop through each message time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'dt (s)')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at where the messages were\n",
    "plt.plot(evTS[:-1],np.diff(evTS),'k.',markersize=1)\n",
    "for i,msg in enumerate(msgTS):\n",
    "    plt.plot([msg,msg],[0,30],'r')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('dt (s)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! These lines look like they run right at the beginning of each block.\n",
    "\n",
    "I will note that these are human generated timestamps, and are thus prone to error. In this case I did a decent job, and I can use these message times to cut up my data into separate chunks, *this is NOT guaranteed to work every time!*\n",
    "\n",
    "Lets revisit our stimulus block labels again, in `msgText`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'site 3: laser test (power on 9.5, analog, bilateral)',\n",
       "       b'block1: optotagging (2,10,25 ms pulse, 100 reps)',\n",
       "       b'block2: clicksWithLaser (0-1V)',\n",
       "       b'block3: contrastLaserInterleaved (2x 15 min reps, frozen noise over contrasts, 25Hz stimulation)',\n",
       "       b'block3: contrastLaserInterleaved (2x 15 min reps, frozen noise over contrasts, 25Hz stimulation)'],\n",
       "      dtype='|S513')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want the block that has our DRC stimuli, these are the ones labelled 'contrastLaserInterleaved'.\n",
    "\n",
    "Notice that there are two with the same label? Remember what I said about human errors... I probably forgot that I had sent the first message and sent it twice, and we can see that there are two message lines right before the last block: those are these two messages.\n",
    "\n",
    "That aside, we just want the last one, which occurs right before the last stimulus block, which is the one we want to analyze.\n",
    "\n",
    "**Try this:**\n",
    "- pull out the timestamp of that last message into a variable called `blockStart`\n",
    "- make a logical mask to select only the evTS greater than our block timestamp, call it `I`\n",
    "- assign our masked timestamps to a variable called `blockEvTS`\n",
    "- make a diff plot of `blockEvTS` as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12018b7d0>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we can use the block labels to extract just the events we want\n",
    "# extract the start of the last block\n",
    "blockStart = msgTS[-1]\n",
    "\n",
    "# get all the events after the last block started\n",
    "I = evTS > blockStart\n",
    "blockEvTS = evTS[I]\n",
    "plt.plot(blockEvTS[:-1],np.diff(blockEvTS),'k.',markersize=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're getting very close to looking at spikes! Bear with me!\n",
    "\n",
    "In the plot you should see two nice lines, and maybe a couple points at the beginning that are off the lines.\n",
    "\n",
    "To better understand this, we need to think about our stimuli...\n",
    "* Each block is 3 seconds and is triggered with a 5ms event pulse.\n",
    "* There are 600 blocks in this particular recording.\n",
    "* This means that an array with just our contrast block events should be 600...\n",
    "\n",
    "What is the length of your `blockEvTS` array?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31202"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(blockEvTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is way too big!\n",
    "\n",
    "This is because we didn't really care which events we put in blockEvTS, we just put all of them after the message we chose.\n",
    "\n",
    "These events include:\n",
    "- stimulus event onsets and offsets (these are on channel 1)\n",
    "- laser event onsets and offsets (these are on channel 4)\n",
    "\n",
    "We want to filter just the stim onsets. We can do this using our `evState` variable. This is an array the same length of our `evTS` array, but it tells you what each event was, 1 is stimOn, -1 is stimOff, 4 is laserOn, -4 is laserOff.\n",
    "\n",
    "**Try this:**\n",
    "1. Mask `evState` using our block index `I` from before into a variable called `blockEvState`.\n",
    "2. Pull out only stimulus onset events from blockEvTS, save them to `stimOn`\n",
    "3. Check the shape, if it's 601, you done good!\n",
    "4. Plot the diff plot of `stimOn` as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1201965d0>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first, pull out only events that are state 1 (stimulus rising)\n",
    "blockEvState = evState[I]\n",
    "\n",
    "stimOn = blockEvTS[blockEvState == 1]\n",
    "stimOn.shape\n",
    "\n",
    "# plot again\n",
    "plt.plot(stimOn[:-1],np.diff(stimOn),'k.',markersize=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SO CLOSE! What does your plot look like?\n",
    "\n",
    "You should see a line at 3s dt, then one dot at 5s. The 3s makes sense, this is the difference between our 3s block onsets!\n",
    "\n",
    "The one dot at 5 is actually a feature of our stim presentation code (thanks Kath!). Each block is preceded by 5 seconds of silence, which is good for splitting blocks and for getting a baseline.\n",
    "\n",
    "For now, we don't need that event, so remove it from `stimOn`, then replot your new diff plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x120199d10>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finally remove the first event, it is a block start indicator\n",
    "stimOn = stimOn[1:]\n",
    "plt.plot(stimOn[:-1],np.diff(stimOn),'k.',markersize=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now you should just see two lines which are microseconds apart. This may look alarming, but it is just a sampling artifact. If you compute `1/fs`, you can see that the top line is just 1 sample longer than the bottom line, so no worries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3333333333333335e-05"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, that was a lot just for events... but now we're finally ready to get to the spikes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPIKES\n",
    "\n",
    "Remember way back in the beginning (it feels like forever ago, this takes a while to write...), we talked about spike times and spike identity. This data is saved in `'_data/spike_times.npy'` and `'_data/spike_clusters.npy'`.\n",
    "\n",
    "Load these files to variables called `spikes` and `clust`, respectively. Look at the values, what are the shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[     152]\n",
      " [     180]\n",
      " [     225]\n",
      " ...\n",
      " [97832635]\n",
      " [97832678]\n",
      " [97832687]]\n",
      "(929663, 1)\n",
      "[160  60 116 ...  49  92  38]\n",
      "(929663,)\n"
     ]
    }
   ],
   "source": [
    "# events are done, now load spike data\n",
    "clust = np.load(os.path.join(root,'spike_clusters.npy'))\n",
    "spikes = np.load(os.path.join(root,'spike_times.npy'))\n",
    "\n",
    "# look at the values, what are their shapes, what do you think they are?\n",
    "print(spikes)\n",
    "print(spikes.shape)\n",
    "print(clust)\n",
    "print(clust.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values in `clust` are actually cell identity indices for each spike. So, it is the same size as `spikes`, and has a numerical value for each spike which tells us what cluster that spike came from.\n",
    "\n",
    "Use this index to extract spikes from `clust == 26` and save in a new variable called `cSpikes`. Print the shape of the spikes for this cell, this corresponds to the number of spikes and look at the spike time values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11283, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  5424],\n",
       "       [ 17830],\n",
       "       [ 17986],\n",
       "       [ 18298],\n",
       "       [ 18457],\n",
       "       [ 18782],\n",
       "       [ 37292],\n",
       "       [ 60120],\n",
       "       [200175],\n",
       "       [200436]], dtype=uint64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = 26\n",
    "\n",
    "cSpikes = spikes[clust == c]\n",
    "print(cSpikes.shape)\n",
    "cSpikes[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values are huge! Again, this is because spikes are recorded in samples from the **recording** onset (*unlike events, which are from the GUI start onset*). Redefine `cSpikes` so that it is in seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cSpikes = cSpikes / fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to know more information about our clusters? KiloSort2/Phy (our sorting software) outputs a file called `'_data/cluster_info.tsv'` that contains info about each cluster.\n",
    "\n",
    "**Try this:**\n",
    "1. Load this file using our old friend pandas, keeping in mind that the delimiters are tabs (hence, .tsv).\n",
    "2. In the group column, you can see that a lot of the cells are labelled as noise... remove those rows from the dataframe\n",
    "3. Save just the `id` column of our filtered data frame to a variable called `clustID`\n",
    "\n",
    "\n",
    "(*we won't actually be using this information, but this seems like a handy thing to know for batch analysis*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the cluster info using pandas\n",
    "clustInfo = pd.read_csv(os.path.join(root,'cluster_info.tsv'),delimiter='\\t')\n",
    "\n",
    "# remove noise clusters\n",
    "clustInfo = clustInfo[clustInfo.group != 'noise']\n",
    "\n",
    "# extract the cell index\n",
    "clustID = np.asarray(clustInfo.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, print the shape of `cSpikes`, which corresponds to the spike count, and look at the dataframe row for this cluster, the column named `n_spikes` should have the same number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11283, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Amplitude</th>\n",
       "      <th>ContamPct</th>\n",
       "      <th>KSLabel</th>\n",
       "      <th>channel</th>\n",
       "      <th>depth</th>\n",
       "      <th>firing_rate</th>\n",
       "      <th>group</th>\n",
       "      <th>n_spikes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>26</td>\n",
       "      <td>639.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>mua</td>\n",
       "      <td>7</td>\n",
       "      <td>775.0</td>\n",
       "      <td>3.5 spk/s</td>\n",
       "      <td>good</td>\n",
       "      <td>11283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  Amplitude  ContamPct KSLabel  channel  depth firing_rate group  \\\n",
       "16  26      639.2      100.0     mua        7  775.0   3.5 spk/s  good   \n",
       "\n",
       "    n_spikes  \n",
       "16     11283  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cSpikes.shape)\n",
    "clustInfo[clustInfo.id==c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## its psth time.\n",
    "\n",
    "Lets get down to analysis, we're ready.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "First, let's make a PSTH, or peri-stimulus time histogram (?), which is just binned spike counts relative to different stimulus onsets.\n",
    "\n",
    "**To start:**\n",
    "1. Define `binSize = .001`.\n",
    "2. Make a variable called `edges` which is **a**   **range** from -.1 to 3.1 seconds, in steps of `binSize`. These are the bin edges of our histogram.\n",
    "3. Make a time vector, which is the center of each pair of edge bins, call it `time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins and edges\n",
    "binSize = .001\n",
    "edges = np.arange(-.1,3.1,binSize)\n",
    "time = edges[:-1] + np.diff(edges).mean() /2    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next:**\n",
    "1. Zero your spikes to the first event in `stimOn` call the zeroed spikes `spks`.\n",
    "2. Use numpy's `histogram` function to make a histogram of these zeroed spikes using our `edges`. Look at the help.\n",
    "3. Plot the histogram counts as a function of `time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x120199f50>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zero spikes on first stim and compute histogram\n",
    "spks = cSpikes - stimOn[0]\n",
    "n,bin_edges = np.histogram(spks,bins=edges)\n",
    "n = n\n",
    "# plot\n",
    "plt.plot(time,n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can see this vector goes to 1 with each spike! What we did was make a histogram for just one contrast block. \n",
    "\n",
    "Use a loop to make a full psth matrix, where each row is one of these block histograms. Make sure to divide each row you make by the binSize to convert to spike rate. Then plot your psth matrix using `plt.imshow` with aspect set to auto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x114f61290>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make it a loop\n",
    "\n",
    "# preallocate\n",
    "psth = np.empty([len(stimOn),len(edges)-1])\n",
    "\n",
    "for i,trig in enumerate(stimOn):\n",
    "    \n",
    "    # zero spikes\n",
    "    spks = cSpikes - trig\n",
    "    \n",
    "    # spike histogram appended to PSTH\n",
    "    psth[i,:],_ = np.histogram(spks,bins=edges)\n",
    "    psth[i,:] = psth[i,:] / binSize\n",
    "\n",
    "    \n",
    "\n",
    "plt.imshow(psth,aspect='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a quick and dirty way of visualizing responses over trials. However, imshow does some funky compression, so maybe a spike raster is a better visualization. Modify your for loop from before to also build a spike raster.\n",
    "\n",
    "**Try this**:\n",
    "1. Create two empty lists, `raster` and `trials`.\n",
    "2. In your loop, populate `raster` with spike times corresponding to that trial (that is, spikes within the limits of edges)\n",
    "3. Also populate `trials` with a trial index for each spike (so, if there are 3 spikes in trial 1, then 2 spikes in trial 2, trials will start as [1 1 1 2 2 ...]\n",
    "\n",
    "(HINT: the list method `append` seems like the obvious choice here, but that will in fact create a list of arrays, when we just want a list of numbers that **extends** on each loop, there is a similarly named list method that can do this...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preallocate\n",
    "raster = []\n",
    "trials = []\n",
    "psth = np.empty([len(stimOn),len(edges)-1])\n",
    "\n",
    "for i,trig in enumerate(stimOn):\n",
    "    \n",
    "    # zero spikes\n",
    "    spks = cSpikes - trig\n",
    "    \n",
    "    # spike histogram appended to PSTH\n",
    "    psth[i,:],_ = np.histogram(spks,bins=edges)\n",
    "    psth[i,:] = psth[i,:] / binSize\n",
    "    \n",
    "    # extend raster (using only spikes within each trial range)\n",
    "    spks = spks[(spks>edges[0]) & (spks<edges[-1])]\n",
    "    raster.extend(spks)\n",
    "    trials.extend(np.ones(len(spks))*(i+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now have a list of spikes that are triggered to each trial event, and a corresponding index of the trial number for each spike. Now it is really easy to plot a raster using `plt.scatter`!\n",
    "\n",
    "Make two subplots, plotting the psth from before in one, and plotting your spike raster in the other (make the raster marker size small, 1 looks good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x124b5a9d0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=[16,4])\n",
    "ax[0].imshow(psth,aspect='auto')\n",
    "ax[1].scatter(raster,trials,1,'k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now we have two representations of our data, one with spike resolution and one with PSTH resolution of 1ms!\n",
    "\n",
    "Now we might want to start testing how different parameters of our stimuli affect neural responses. To do this we need to know what stimulus was played for each of our 600 trials.\n",
    "\n",
    "This information is saved in `'_data/trialOrder.npy'`. Load this file into a variable called `order`. It should be 3 columns, with column 1 == 1 during low contrast and 2 during high contrast, column 2 == 0 when laser is off and 1 when on, and column 3 is a frozen noise pattern for the DRC.\n",
    "\n",
    "How long is order?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stimulus info and sort by noise pattern\n",
    "import numpy.matlib\n",
    "order = np.load(os.path.join(root,'trialOrder.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `order` is 300 long? This is only half the length of our recorded event number (600). This is because I save a fixed order of the stimulus in 1 file, and repeat that as time allows for a recording; here I had two repeats.\n",
    "\n",
    "To fix this, redefine `order` to be the same matrix repeated twice, your new `order` will be 600 rows x 3 columns. (there are several ways to achieve this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order = np.matlib.repmat(order,2,1)\n",
    "order.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know what stimuli were played when, and we can use order to index trials in our PSTH for averaging.\n",
    "\n",
    "**Try this**:\n",
    "1. Make an index for contrast from `order`.\n",
    "2. Use the index to make an average PSTH response for low and high contrast.\n",
    "3. Plot these means, in blue for low and red for high. Make sure to plot with the right time axis. There's a lot of overlap here, and the data aren't smoothed, so you can also play with the xlim to look only at the first 1s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(time,psth[order[:,0]==1,:].mean(axis=0),'b')\n",
    "plt.plot(time,psth[order[:,0]==2,:].mean(axis=0),'r')\n",
    "plt.xlim([0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try to quickly visualize the effects of contrast AND laser.\n",
    "\n",
    "**Try this:**\n",
    "1. Make a figure with two subplots.\n",
    "2. In the first subplot, plot the mean temporal response during low contrast with the laser off in blue, and low contrast with laser on in black.\n",
    "3. Do the same in the second subplot, but for high contrast, and color the laser off curve red.\n",
    "4. Remember axis labels and titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'High Contrast')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=[12,4])\n",
    "\n",
    "ax[0].plot(time,psth[(order[:,0]==1)&(order[:,1]==0),:].mean(axis=0),'b')\n",
    "ax[0].plot(time,psth[(order[:,0]==1)&(order[:,1]==1),:].mean(axis=0),'k')\n",
    "ax[0].set_xlim([0,1])\n",
    "ax[0].set_xlabel('Time (s)')\n",
    "ax[0].set_ylabel('FR (Hz)')\n",
    "ax[0].set_title('Low Contrast')\n",
    "\n",
    "ax[1].plot(time,psth[(order[:,0]==2)&(order[:,1]==0),:].mean(axis=0),'r')\n",
    "ax[1].plot(time,psth[(order[:,0]==2)&(order[:,1]==1),:].mean(axis=0),'k')\n",
    "ax[1].set_xlim([0,1])\n",
    "ax[1].set_xlabel('Time (s)')\n",
    "ax[1].set_ylabel('FR (Hz)')\n",
    "ax[1].set_title('High Contrast')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we've converted our spike data into a PSTH matrix that is really easy to work with. I think this covers the basics of getting started with analysis, most of my analyses stem from using these PSTH matrices.\n",
    "\n",
    "In this last part, I want to cover a bit more advanced visualization of the raw data. PSTHs are nice, but they are not quite as nice as seeing your effects in a spike raster! I think presenting spike rasters in a way that can show stimulus effects is very valuable!\n",
    "\n",
    "The approach I usually take is to sort my rasters by different conditions, this lets you see by eye how the spike patterns change.\n",
    "\n",
    "First, we want to generate a sorting index. This will rearrange our trials such that all the trials of one type are presented together, then all the trials of the next type and so on. \n",
    "\n",
    "**Goal:**\n",
    "Create an index to sort our trials by contrast condition.\n",
    "\n",
    "There is a numpy function for this, and it is not called `sort`, but does have the word sort in it... if you run `np.sort`, it will return just a sorted version of the vector you give it, we want the trial order that gives this sorting.\n",
    "\n",
    "**IMPORTANT:** once you get your sorting index, add 1 to it... this will make trial 1 == 1, trial 2 == 2 etc., which is necessary later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortI = np.argsort(order[:,0])+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick and dirty method of visualizing the effect of sorting is to sort and plot your PSTH with your index, but this doesn't look great, lets try sorting the raster next:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1201a4950>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(psth[sortI-1,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we want to do is take our `trials` variable, and resort it according to `sortI`. There is a REALLY easy way to do this in matlab with the `ismember` function, but python doesn't have anything similar to that. I've written a function that sort of replicates this functionality below (see the comments for what this function does)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aside: writing external functions\n",
    "def ismember(A,B):\n",
    "    \"\"\"replaces values in A with the index of their matches in B\"\"\"\n",
    "\n",
    "    # This function takes two arrays, A and B, and checks for matches.\n",
    "    # Where A matches B, those values of A are replaced by their index in B.\n",
    "    # This index is returned in res.\n",
    "\n",
    "    # convert both A and B to np arrays\n",
    "    A = np.asarray(A).astype(int)\n",
    "    B = np.asarray(B).astype(int)\n",
    "\n",
    "    # preallocate res\n",
    "    res = np.zeros(A.shape)\n",
    "\n",
    "    # loop through unique values of A\n",
    "    for i in np.unique(A):\n",
    "\n",
    "        # where A == i, replace them with the index of i in B\n",
    "        res[A == i] = np.argwhere(B == i).squeeze()\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try this:**\n",
    "1. Run this function on our data, to sort `trials` by `sortI`, setting the new sorted trials to `sortSpikeTrials`.\n",
    "2. Plot the sorted version of the raster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1152e1810>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortSpikeTrials = ismember(trials,sortI)\n",
    "plt.scatter(raster,sortSpikeTrials,1,'k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see a really distinct split between the top and bottom half of the data, reflecting the timecourse of our PSTH averages from before, neat!\n",
    "\n",
    "Now do the same thing, but instead of sorting by contrast, sort by laser (column 2 of order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x124b6e8d0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortI = np.argsort(order[:,1])+1\n",
    "spikeSortI = ismember(trials,sortI)\n",
    "\n",
    "plt.scatter(raster,spikeSortI,1,'k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, visualize the sorting by noise pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x11ebd0c10>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortI = np.argsort(order[:,2])+1\n",
    "spikeSortI = ismember(trials,sortI)\n",
    "\n",
    "plt.scatter(raster,spikeSortI,1,'k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! While visualizing the rasters this way is not necessary for analyzing your data, I find it very useful and a good way to make pretty figures for publication.\n",
    "\n",
    "Now, you might want to save some of this data for later analysis. Remember in previous tutorials we covered the pickle method in Python. From what I understand, pickling is a way of saving variables in a file, like we would save Matlab variables in a .mat file. For easy access, lets pickle our data for later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = os.path.join(root,'sessionInfo.pkl')\n",
    "\n",
    "# remember this `with` command cleanly closes files once they've been opened, even if there is a write error\n",
    "with open(fn,'wb') as f:\n",
    "    pickle.dump([order, clustInfo, fs, stimOn],f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
